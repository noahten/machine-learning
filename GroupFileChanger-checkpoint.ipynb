{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfkakita=pd.read_csv('kakita_reshape.csv',encoding=\"shift-jis\")\n",
    "dfyahagi=pd.read_csv('yahagi_reshape.csv',encoding=\"shift-jis\")\n",
    "dfiwase=pd.read_csv('iwase_reshape.csv',encoding=\"shift-jis\")\n",
    "dfsimada=pd.read_csv('simada_reshape.csv',encoding=\"shift-jis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rekakita=dfkakita.drop(\"TimeStamp\", axis=1)\n",
    "df_reyahagi=dfyahagi.drop(\"TimeStamp\", axis=1)\n",
    "df_reiwase=dfiwase.drop(\"TimeStamp\", axis=1)\n",
    "df_resimada=dfsimada.drop(\"TimeStamp\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rekakita=df_rekakita.dropna(how='all', axis=1)\n",
    "df_reyahagi=df_reyahagi.dropna(how='all', axis=1)\n",
    "df_reiwase=df_reiwase.dropna(how='all', axis=1)\n",
    "df_resimada=df_resimada.dropna(how='all', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#欠損値があるかどうか調べる\n",
    "df_rekakita=df_rekakita.dropna(how='any').dropna(how='all')\n",
    "df_reyahagi=df_reyahagi.dropna(how='any').dropna(how='all')\n",
    "df_reiwase=df_reiwase.dropna(how='any').dropna(how='all')\n",
    "df_resimada=df_resimada.dropna(how='any').dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#各データセット連結\n",
    "df=pd.concat([df_rekakita,df_reyahagi,df_reiwase,df_resimada ], axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re=df['label3']\n",
    "df_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#realsenseデータをデータフレームに読み込む\n",
    "dfkakita_real=pd.read_csv('kakita_re_syori1.csv',encoding=\"shift-jis\")\n",
    "dfyahagi_real=pd.read_csv('yahagi_re_shori1.csv',encoding=\"shift-jis\")\n",
    "dfiwase_real=pd.read_csv('iwase_re_shori1.csv',encoding=\"shift-jis\")\n",
    "dfsimada_real=pd.read_csv('simada_re_shori1.csv',encoding=\"shift-jis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特定の行の欠損値削除\n",
    "dfkakite_real_re=dfkakita_real.dropna(subset=['timeRe']).dropna(how='all', axis=1)\n",
    "dfyahagi_real_re=dfyahagi_real.dropna(subset=['timeRe']).dropna(how='all', axis=1)\n",
    "dfiwase_real_re=dfiwase_real.dropna(subset=['timeRe']).dropna(how='all', axis=1)\n",
    "dfsimada_real_re=dfsimada_real.dropna(subset=['timeRe']).dropna(how='all', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfkakite_real_re.reset_index(drop=True, inplace=True)\n",
    "dfyahagi_real_re.reset_index(drop=True, inplace=True)\n",
    "dfiwase_real_re.reset_index(drop=True, inplace=True)\n",
    "dfsimada_real_re.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfkakite_real_re2=dfkakite_real_re.drop(dfkakite_real_re.index[[range(1,188)]])\n",
    "dfyahagi_real_re2=dfyahagi_real_re.drop(dfyahagi_real_re.index[[range(1,114)]])\n",
    "dfiwase_real_re2=dfiwase_real_re.drop(dfiwase_real_re.index[[range(1,1212)]])\n",
    "dfsimada_real_re2=dfsimada_real_re.drop(dfsimada_real_re.index[[range(1,858)]])\n",
    "dfkakite_real_re2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfkakite_real_re2.reset_index(drop=True, inplace=True)\n",
    "dfyahagi_real_re2.reset_index(drop=True, inplace=True)\n",
    "dfiwase_real_re2.reset_index(drop=True, inplace=True)\n",
    "dfsimada_real_re2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#各データセット連結\n",
    "dfrealsense_re3=pd.concat([dfkakite_real_re2,dfyahagi_real_re2,dfiwase_real_re2,dfsimada_real_re2], axis=0)\n",
    "dfrealsense_re3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrealsense_re3=dfrealsense_re3.drop(dfrealsense_re3.columns[[0,1,424]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrealsense_re3.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#表情データと脳波データ連結\n",
    "dfconnect=pd.concat([df_re, dfrealsense_re3], axis=1)\n",
    "dfconnect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfconnect=dfconnect.dropna(how='any')\n",
    "dfconnect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfconnect.reset_index(drop=True, inplace=True)\n",
    "dfconnect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV ファイル (employee.csv) として出力\n",
    "dfconnect.to_csv(\"dfconnectGrupK_label3.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アンダーサンプリング resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFeatures = pd.read_csv('dfconnectGrupK_label3.csv',encoding=\"shift-jis\")\n",
    "dfFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#要素の個数はｃｓｖで確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0が多い場合\n",
    "#1を削除0からランダムに抽出\n",
    "dfFeatures2 = dfFeatures.drop(dfFeatures[dfFeatures['label3'] == 1.0].index)\n",
    "#1が多い場合\n",
    "#0を削除1からランダムに抽出\n",
    "#dfFeatures2 = dfFeatures.drop(dfFeatures[dfFeatures['ZscorePosNeg2'] == 0.0].index)\n",
    "dfFeatures2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0ラベルのクラスをダウンサンプリング\n",
    "#dfFeatures_resample = dfFeatures2.sample(n=287, random_state=1)\n",
    "#dfFeatures_resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ラベル1のクラスを抽出して結合\n",
    "#0が多い場合\n",
    "dfFeatures3 = dfFeatures.drop(dfFeatures[dfFeatures['label3'] == 0.0].index)\n",
    "#1が多い場合\n",
    "#dfFeatures3 = dfFeatures.drop(dfFeatures[dfFeatures['Question'] == 1.0].index)\n",
    "dfFeatures3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ランダムに結合部分\n",
    "# データをマージする\n",
    "dfconnect_undersampled = pd.concat([dfFeatures3,dfFeatures2], ignore_index=True)\n",
    "pd.DataFrame(dfconnect_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#本のupsampling手法\n",
    "#from sklearn.utils import resample\n",
    "#print('Number of class 1 samples before:' ,  X[y == 1].shape[0])\n",
    "#サンプルの個数がクラス0と同じになるまで新しいサンプルを復元抽出します\n",
    "#X_upsampled, y_upsampled = resample(X[y == 1],y[y == 1],resample = True, n_samples=X[y == 0].shape[0],random_state=1)\n",
    "#print('Number of class1 samples after:' , X_upsampled.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #p117\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17列目から学習データ\n",
    "X,y =dfconnect_undersampled.iloc[:,1:].values,dfconnect_undersampled.iloc[:,0].values\n",
    "#トレーニングデータとテストデータに分割\n",
    "#全体の10%をテストデータにする\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, \n",
    "                     test_size=0.3, \n",
    "                     random_state=1, \n",
    "                     stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ランダムフォレスト\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "feat_labels=dfconnect.columns[1:]\n",
    "forest = RandomForestClassifier(n_estimators=500,random_state=1)\n",
    "forest.fit(X_train,y_train)\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 424, \n",
    "                            feat_labels[indices[f]], \n",
    "                            importances[indices[f]]))\n",
    "\n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(X_train.shape[1]), \n",
    "        importances[indices],\n",
    "        align='center')\n",
    "\n",
    "plt.xticks(range(X_train.shape[1]), \n",
    "           feat_labels[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/04_09.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "決定木"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "y_train_binarized = lb.fit_transform(y_train)\n",
    "y_train_binarized = y_train_binarized.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train,y_train_binarized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ランダムフォレスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=0)\n",
    "\n",
    "\n",
    "tuned_parameters = [\n",
    "    {'criterion':['entropy','gini'],\n",
    "    'max_depth':list(range(1,30)),\n",
    "    'n_estimators':[10,20,30,40,50,60,70,80,90,100]}\n",
    "\n",
    "    ]\n",
    "\n",
    "score = 'f1'\n",
    "clf = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=0), # 識別器\n",
    "    tuned_parameters, # 最適化したいパラメータセット \n",
    "    cv=10, # 交差検定の回数\n",
    "    scoring='%s_weighted' % score ) # モデルの評価関数の指定\n",
    "\n",
    "clf.fit(X_train, y_train) \n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n",
    "y_true_train, y_pred_train = y_train, clf.predict(X_train)\n",
    "print (classification_report(y_true_train, y_pred_train))  # クラスタリング結果を表示\n",
    "print (confusion_matrix(y_true_train, y_pred_train))       # クラスタリング結果を表示\n",
    "\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print (classification_report(y_true, y_pred))  # クラスタリング結果を表示\n",
    "print (confusion_matrix(y_true, y_pred))       # クラスタリング結果を表示\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グリッドサーチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                        PCA(),\n",
    "                        LogisticRegression(random_state=1))\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred = pipe_lr.predict(X_test)\n",
    "print('Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10分割交差検証\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=pipe_lr,\n",
    "                         X=X_train,\n",
    "                         y=y_train,\n",
    "                         cv=10,\n",
    "                         n_jobs=-1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "混合行列・適合率再現率F値・ROC曲線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#混合行列\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pipe_lr.fit(X_train,y_train)\n",
    "y_pred = pipe_lr.predict(X_test)\n",
    "#テストと予測のデータから混合行列を生成\n",
    "confmat = confusion_matrix(y_true = y_test,y_pred = y_pred)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#図表示\n",
    "fig, ax=plt.subplots(figsize = (2.5,2.5))\n",
    "ax.matshow(confmat,cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j,y=i,s=confmat[i,j],va='center',ha='center')\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('image/GroupK_matrix_label3.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#適合率再現率\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score,f1_score\n",
    "print('Precision: %.3f' % precision_score(y_true = y_test,y_pred=y_pred))\n",
    "print('Recall: %.3f' % recall_score(y_true=y_test,y_pred=y_pred))\n",
    "print('F1: %.3f' % f1_score(y_true=y_test,y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC曲線\n",
    "#L2(l2)正則化\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "pipe_lr=make_pipeline(StandardScaler(),PCA(n_components=2),LogisticRegression(penalty='l2',random_state=1,C=100.0))\n",
    "#２つの特徴量抽出\n",
    "X_train2 = X_train[:,[4,14]]\n",
    "#層化k分割交差検証イテレータを表す StratifiedKFoldクラスをインスタンス化\n",
    "cv  = list(StratifiedKFold(n_splits = 3, random_state=1).split(X_train,y_train))\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "mean_tpr=0.0\n",
    "#0~1 までの間で100個の要素を生成\n",
    "mean_fpr=np.linspace(0,1,100)\n",
    "all_tpr = []\n",
    "for i,(train,test) in enumerate(cv):\n",
    "    #predict_probaメソッドで確率を予測，fitメソッドでモデルに適合させる\n",
    "    probas = pipe_lr.fit(X_train2[train],y_train[train]).predict_proba(X_train2[test])\n",
    "    #roc_curve関数でROC曲線の性能を計算してプロット\n",
    "    fpr,tpr,thresholds = roc_curve(y_train[test],probas[:,1],pos_label=1)\n",
    "    mean_tpr += interp(mean_fpr,fpr,tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "    plt.plot(fpr,tpr,label='ROC fold %d (area = %0.2f)' % (i+1,roc_auc))\n",
    "    \n",
    "#当て推量プロット\n",
    "plt.plot([0 ,1],[0, 1], linestyle='--', color=(0.6,0.6,0.6), label = 'random guesting')\n",
    "\n",
    "#FPR TPR ROC AUCそれぞれの平均を計算してプロット\n",
    "mean_tpr /= len(cv)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, 'k--',\n",
    "         label='mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
    "plt.plot([0, 0, 1],\n",
    "         [0, 1, 1],\n",
    "         linestyle=':',\n",
    "         color='black',\n",
    "         label='perfect performance')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('image/GroupK_ROC_label3.png', dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
